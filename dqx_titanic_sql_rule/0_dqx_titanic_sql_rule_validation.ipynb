{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## üõ≥Ô∏è Validaci√≥n de Datos en Titanic con DQX (Regla SQL)  \n",
        "\n",
        "**Dataset usado:** [Titanic_Train.csv](https://raw.githubusercontent.com/lucasmengual92/datasets/main/data/titanic_train.csv)  \n",
        "\n",
        "**Regla SQL:** La columna `Fare` debe ser mayor que cero.\n",
        "\n",
        "**Regla BONUS:** \"La columna `Embarked` deben tener valores `C`, `Q`, o `S`.\n",
        "\n",
        "**Basado en:** [DQX-Data Quality Framework](https://databrickslabs.github.io/dqx/)\n",
        "\n",
        "**Pre-requisitos:** Tener una cuenta/workspace en Databricks.\n",
        "\n",
        "### 0. Instalacion PYPI y Restart Kernel\n",
        "- Si el la 1ra vez:\n",
        "  - !pip install databricks-labs-dqx\n",
        "- Muy probable que tendras que reiniciar el kernel de tu entorno Python para que DQX se instale correctacmete."
      ],
      "metadata": {
        "id": "J0IC9FC_hW3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install databricks-labs-dqx"
      ],
      "metadata": {
        "id": "vWdZ3x7Ij04V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbutils.library.restartPython()"
      ],
      "metadata": {
        "id": "2BBkxWommbjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Cargar el Dataset de Titanic"
      ],
      "metadata": {
        "id": "qkH_vCRziIAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import pandas as pd\n",
        "from databricks.labs.dqx.engine import DQEngine\n",
        "from databricks.sdk import WorkspaceClient"
      ],
      "metadata": {
        "id": "C7vtCroojYlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ud4x9LGg-Sw"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/lucasmengual92/datasets/main/data/titanic_train.csv\"\n",
        "\n",
        "df = pd.read_csv(url, delimiter=\",\", header=0)\n",
        "sdf = spark.createDataFrame(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar esquema y ejemplo de datos\n",
        "print(\"Esquema del dataset:\")\n",
        "sdf.printSchema()\n",
        "print(\"\\nMuestra de datos:\")\n",
        "display(sdf)"
      ],
      "metadata": {
        "id": "bsah8S4hhWeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Definir Regla de Calidad con DQX"
      ],
      "metadata": {
        "id": "ZjyHtNRoh7EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir las Reglas de Calidad (YAML)\n",
        "dqx_checks = yaml.safe_load(\"\"\"\n",
        "- check:\n",
        "    function: sql_expression\n",
        "    arguments:\n",
        "      expression: Fare <= 0\n",
        "      msg: Fare es menor o igual que 0\n",
        "  criticality: error\n",
        "- check:\n",
        "    function: value_is_in_list\n",
        "    arguments:\n",
        "      col_names:\n",
        "        - Embarked\n",
        "      allowed:\n",
        "      - C\n",
        "      - Q\n",
        "      - S\n",
        "  criticality: error\n",
        "  \"\"\")\n",
        "\n",
        "# validate the checks\n",
        "status = DQEngine.validate_checks(dqx_checks)\n",
        "assert not status.has_errors\n",
        "\n",
        "dq_engine = DQEngine(WorkspaceClient())\n",
        "\n",
        "# apply quality checks\n",
        "safe_df, quarantine_df = dq_engine.apply_checks_by_metadata_and_split(sdf, dqx_checks)"
      ],
      "metadata": {
        "id": "g_fm1rvkQ5uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Resultados"
      ],
      "metadata": {
        "id": "8oESQByvmrho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"‚ñ∫ Filas v√°lidas: {safe_df.count()}\")\n",
        "print(f\"‚ñ∫ Filas inv√°lidas: {quarantine_df.count()}\")"
      ],
      "metadata": {
        "id": "cHemlQyyjuzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(quarantine_df)"
      ],
      "metadata": {
        "id": "Fq0Mao0Cm2Ug"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}